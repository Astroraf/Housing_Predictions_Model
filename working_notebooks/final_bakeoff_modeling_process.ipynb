{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kings County Housing Prices Bakeoff\n",
    "\n",
    "Below are a list of steps that you should take while trying to complete your bake-off entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm \n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.read_csv('kc_house_data_train.csv')\n",
    "zipfile = \"Zip_Codes-shp\"\n",
    "street_map = gpd.read_file(zipfile)\n",
    "crs = {'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1 = hf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_grade = pd.read_csv('Niche.csv')\n",
    "hf = zip_grade.set_index('zipcode').join(hf.set_index('zipcode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.dropna(subset = ['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis \n",
    "    \n",
    "Become familiar with the data.  Look to see if there are any extreme values.  \n",
    "\n",
    "Additionally create data visualizations to determine if there are any relationships between your features and your target variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram\n",
    "sns.distplot(hf['price'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(hf['price'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(hf['price'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % hf['price'].skew())\n",
    "print(\"Kurtosis: %f\" % hf['price'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(hf['price'],hf['bathrooms'], scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7,2, figsize = (20, 20))\n",
    "\n",
    "\n",
    "sns.boxplot(ax = axes[0,0], data = hf['bedrooms'], orient = 'h')\n",
    "sns.boxplot(ax = axes[0,1], data = hf['bathrooms'], orient = 'h')\n",
    "sns.boxplot(ax = axes[1,0], data = hf['sqft_living'], orient = 'h')\n",
    "sns.boxplot(ax = axes[1,1], data = hf['sqft_lot'], orient = 'h')\n",
    "sns.boxplot(ax = axes[2,0], data = hf['floors'], orient = 'h')\n",
    "sns.boxplot(ax = axes[2,1], data = hf['grade'], orient = 'h')\n",
    "sns.boxplot(ax = axes[3,0], data = hf['sqft_above'], orient = 'h')\n",
    "sns.boxplot(ax = axes[3,1], data = hf['sqft_basement'], orient = 'h')\n",
    "sns.boxplot(ax = axes[4,0], data = hf['yr_built'], orient = 'h')\n",
    "sns.boxplot(ax = axes[4,1], data = hf['yr_renovated'], orient = 'h')\n",
    "sns.boxplot(ax = axes[5,0], data = hf['zipcode'], orient = 'h')\n",
    "sns.boxplot(ax = axes[5,1], data = hf['sqft_living15'], orient = 'h')\n",
    "sns.boxplot(ax = axes[6,0], data = hf['sqft_lot15'], orient = 'h')\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['price', 'sqft_living', 'sqft_lot', 'view',\n",
    "             'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "categorical = ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'condition', 'grade', 'zipcode']\n",
    "\n",
    "hf1 = hf1[numerical + categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(30, 20))\n",
    "for var, subplot in zip(categorical, ax.flatten()):\n",
    "    sns.boxplot(x=var, y='price', data=hf1, ax=subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(hf):\n",
    "    _,ax=plt.subplots(figsize=(25,20))\n",
    "    colormap=sns.diverging_palette(220,10,as_cmap=True)\n",
    "    sns.heatmap(hf.corr(),annot=True,cmap=colormap)\n",
    "    \n",
    "correlation_heatmap(hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean up any issues (extreme values, etc.) with the data.  \n",
    "\n",
    "Remember that you can't just delete rows with extreme values. Similar observations might be present in the holdout data set, and you can't just delete those rows and not have a prediction for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15243.3998843262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142157.2712491516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_lot_mean = hf['sqft_lot'].mean()\n",
    "print(sq_lot_mean)\n",
    "sq_lot_std3 = hf['sqft_lot'].std()*3\n",
    "sq_lot_mstd = sq_lot_mean + sq_lot_std3\n",
    "\n",
    "sq_lot_mstd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2081.4646038172355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4841.520222012694"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_living_mean = hf['sqft_living'].mean()\n",
    "print(sq_living_mean)\n",
    "sq_living_std3 = hf['sqft_living'].std()*3\n",
    "sq_living_mstd = sq_living_mean + sq_living_std3\n",
    "sq_living_mstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789.306015037594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4277.101336107848"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_above_mean = hf['sqft_above'].mean()\n",
    "print(sq_above_mean)\n",
    "sq_above_std3 = hf['sqft_above'].std()*3\n",
    "sq_above_mstd = sq_above_mean + sq_above_std3\n",
    "\n",
    "sq_above_mstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292.15858877964143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1621.61421219585"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_base_mean = hf['sqft_basement'].mean()\n",
    "print(sq_base_mean)\n",
    "sq_base_std3 = hf['sqft_basement'].std()*3\n",
    "sq_base_mstd = sq_base_mean + sq_base_std3\n",
    "sq_base_mstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_sqft(row):\n",
    "    if row['sqft_lot'] > sq_lot_mstd:\n",
    "        row['sqft_lot'] = sq_lot_mstd\n",
    "    if row['sqft_living'] > sq_living_mstd:\n",
    "        row['sqft_living'] = sq_living_mstd\n",
    "    if row['sqft_above'] > sq_above_mstd :\n",
    "        row['sqft_above'] = sq_above_mstd\n",
    "    if row['sqft_basement'] > sq_base_mstd :\n",
    "        row['sqft_basement'] = sq_base_mstd \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(cap_sqft, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_val_bed_bath(row):\n",
    "    \"\"\"\n",
    "    Checking extreame number of rooms in the house\n",
    "    \"\"\"\n",
    "    if row['bedrooms'] == 0:\n",
    "        row['bedrooms'] = row['floors']\n",
    "    if row['bathrooms'] < 1:\n",
    "        row['bathrooms'] = 1\n",
    "    if row['bedrooms'] > 10 :\n",
    "        row['bedrooms'] = 10\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(zero_val_bed_bath, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.drop(columns = ['zip_rank', 'Unnamed: 0', 'id', 'view', 'sqft_living15', 'sqft_lot15'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_niche_grade(row):\n",
    "    \n",
    "    if row['niche_grade'] == 'A+':\n",
    "        row['niche_grade'] = 1\n",
    "    if row['niche_grade'] == 'A+ ':\n",
    "        row['niche_grade'] = 1\n",
    "    if row['niche_grade'] == 'A':\n",
    "        row['niche_grade'] = 2\n",
    "    if row['niche_grade'] == 'A-':\n",
    "        row['niche_grade'] = 3\n",
    "    if row['niche_grade'] == 'B+':\n",
    "        row['niche_grade'] = 4\n",
    "    if row['niche_grade'] == 'B':\n",
    "        row['niche_grade'] = 5\n",
    "    if row['niche_grade'] == 'B-':\n",
    "        row['niche_grade'] = 6\n",
    "    \n",
    "    return row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(define_niche_grade, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_school_grade(row):\n",
    "    \n",
    "    if row['school_grade'] == 'A+':\n",
    "        row['school_grade'] = 1\n",
    "    if row['school_grade'] == 'A+ ':\n",
    "        row['school_grade'] = 1\n",
    "    if row['school_grade'] == 'A ':\n",
    "        row['school_grade'] = 2\n",
    "    if row['school_grade'] == 'A':\n",
    "        row['school_grade'] = 2\n",
    "    if row['school_grade'] == 'A-':\n",
    "        row['school_grade'] = 3\n",
    "    if row['school_grade'] == 'A- ':\n",
    "        row['school_grade'] = 3\n",
    "    if row['school_grade'] == 'B+':\n",
    "        row['school_grade'] = 4\n",
    "    if row['school_grade'] == 'B':\n",
    "        row['school_grade'] = 5\n",
    "    if row['school_grade'] == 'B-':\n",
    "        row['school_grade'] = 6\n",
    "    if row['school_grade'] == 'C+':\n",
    "        row['school_grade'] = 7\n",
    "    \n",
    "    return row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(define_school_grade, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate new features that you think could be important.\n",
    "\n",
    "After doing this, you will want to go back to steps 2 and 3 to investigate these new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['yr_updated'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yr_update(row):\n",
    "    \n",
    "    if row['yr_renovated'] == 0:\n",
    "        row['yr_updated'] = 2021 - row['yr_built']\n",
    "    if row['yr_renovated'] != 0:\n",
    "        row['yr_updated'] = 2021 - row['yr_built']\n",
    "        \n",
    "    return row \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(yr_update, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['percent_bedbath'] = np.nan\n",
    "hf['has_golden_ratio'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ratio_range(row):\n",
    "    golden_ratio = (2/3)\n",
    "    golden_ratio_plus = golden_ratio + (golden_ratio * .10)\n",
    "    golden_ratio_minus = golden_ratio - (golden_ratio * .10)\n",
    "    \n",
    "    if row['percent_bedbath'] <= golden_ratio_plus and row['percent_bedbath'] >= golden_ratio_minus:\n",
    "            row['has_golden_ratio'] = 1\n",
    "    else:\n",
    "        row['has_golden_ratio'] = 0\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(cal_ratio_range, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off of bathrooms pros and housetipster \n",
    "\n",
    "def ratio_bed_bath(row):\n",
    "    \n",
    "    ratio_bed_bath = row['bathrooms'] / row['bedrooms']\n",
    "    golden_ratio = (2/3)\n",
    "    row['percent_bedbath'] = abs(golden_ratio - ratio_bed_bath) \n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(ratio_bed_bath, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['ratio_liv_lot'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_living_lot(row):\n",
    "    \n",
    "    row['ratio_liv_lot'] = row['sqft_lot'] / row['sqft_living']\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(ratio_living_lot, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train-Test Split\n",
    "\n",
    "If you plan on doing any scaling of your data, make sure it is done at the appropriate time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.concat([hf, pd.get_dummies(hf['zipcode'])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.drop(columns = 'zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.concat([hf, pd.get_dummies(hf['grade'])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.drop(columns = 'grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns = hf.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest g: 1\n",
    "# low g: 3 Falls short of minimum building standards. Normally cabin or inferior structure.\n",
    "\n",
    "# dnmc: 4 Generally older, low quality construction. Does not meet code.\n",
    "\n",
    "# poor: 5 Low construction costs and workmanship. Small, simple design.\n",
    "\n",
    "# bare_min: 6 Lowest grade currently meeting building code. Low quality materials and simple designs.\n",
    "\n",
    "# average: 7 Average grade of construction and design. Commonly seen in plats and older sub-divisions.\n",
    "\n",
    "# above_avg: 8 Just above average in construction and design. Usually better materials in both the exterior and interior finish work.\n",
    "\n",
    "# good: 9 Better architectural design with extra interior and exterior design and quality.\n",
    "\n",
    "# high_qua: 10 Homes of this quality generally have high quality features. Finish work is better and more design quality is seen in the floor plans. Generally have a larger square footage.\n",
    "\n",
    "# higher_qua: 11 Custom design and higher quality finish work with added amenities of solid woods, bathroom fixtures and more luxurious options.\n",
    "\n",
    "# excellent qua: 12 Custom design and excellent builders. All materials are of the highest quality and all conveniences are present.\n",
    "\n",
    "# mansion: 13 Generally custom designed and built. Mansion level. Large amount of highest quality cabinet work, wood trim, marble, entry ways etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.rename(columns={'1': 'lowest_g', '3': 'low_g', '4':'dnmc', '5':'Poor', '6':'bare_min', \n",
    "                   '7':'average', '8':'above_avg', '9':'good', '10':'high_qua', '11':'higher_qua',\n",
    "                   '12':'excellent_qua', '13':'mansion' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# waterfront times sqft_lot\n",
    "hf = pd.concat([hf, pd.get_dummies(hf['waterfront'])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.rename(columns={0: \"No_Waterfront\", 1: \"Waterfront\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['water_sqft_lot'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_lot(row):\n",
    "    if row['waterfront'] == 1:\n",
    "        row['water_sqft_lot'] = row['Waterfront'] * row['sqft_lot'] \n",
    "    if row['waterfront'] == 0:\n",
    "        row['water_sqft_lot'] = 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(water_lot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.drop(columns='waterfront')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['school_grade', 'population', \n",
    "             'bedrooms', 'bathrooms', \n",
    "            'sqft_living', 'sqft_lot', 'floors', 'condition', 'sqft_above', \n",
    "            'sqft_basement', 'yr_built', 'yr_renovated', \n",
    "            'percent_bedbath','has_golden_ratio', 'lowest_g','low_g', 'dnmc', 'Poor', \n",
    "            'bare_min', 'average', 'above_avg', 'good', 'high_qua', 'higher_qua', \n",
    "            'excellent_qua', 'mansion', 'No_Waterfront',  'Waterfront', 'water_sqft_lot',\n",
    "            '98001', '98002', '98003', '98004', '98005', '98006',\n",
    "           '98007', '98008', '98010', '98011', '98014', '98019', '98022', '98023',\n",
    "           '98024', '98027', '98028', '98029', '98030', '98031', '98032', '98033',\n",
    "           '98034', '98038', '98039', '98040', '98042', '98045', '98052', '98053',\n",
    "           '98055', '98056', '98058', '98059', '98065', '98070', '98072', '98074',\n",
    "           '98075', '98077', '98092', '98102', '98103', '98105', '98106', '98107',\n",
    "           '98108', '98109', '98112', '98115', '98116', '98117',\n",
    "           '98118', '98119', '98122', '98125', '98126', '98133', '98136', '98144',\n",
    "           '98146', '98148', '98155', '98166', '98168', '98177', '98178', '98188',\n",
    "           '98198', '98199']\n",
    "\n",
    "hf_features = hf[features]\n",
    "target = hf['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(df, features, target):\n",
    "    df_features = df[features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=34,test_size=0.2)\n",
    "    #instantiate a linear regression object\n",
    "    lm = linear_model.LinearRegression()\n",
    "\n",
    "    #fit the linear regression to the data\n",
    "    lm = lm.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = lm.predict(X_train)\n",
    "    \n",
    "    train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "    train_mse = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "   \n",
    "    # Test Set\n",
    "    y_pred = lm.predict(X_test)\n",
    "    \n",
    "    #test_mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    #print('Mean Absolute Error:' + str(metrics.mean_absolute_error(y_test, y_pred)))\n",
    "    #print('Mean Squared Error:' + str(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  160137 vs. Testing:  155432\n"
     ]
    }
   ],
   "source": [
    "model_test(hf, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['niche_grade', 'yr_updated', 'ratio_liv_lot']\n",
    "\n",
    "hf_poly = hf[features]\n",
    "target = hf['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_data = poly.fit_transform(hf_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_columns = poly.get_feature_names(hf_poly.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly = pd.DataFrame(poly_data, columns=poly_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['niche_grade',\n",
       " 'yr_updated',\n",
       " 'ratio_liv_lot',\n",
       " 'niche_grade^2',\n",
       " 'niche_grade yr_updated',\n",
       " 'niche_grade ratio_liv_lot',\n",
       " 'yr_updated^2',\n",
       " 'yr_updated ratio_liv_lot',\n",
       " 'ratio_liv_lot^2']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([hf_features, df_poly], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17290, 108)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Utilize some different feature selection techniques before or in conjuction with fitting your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_feat = ['school_grade', 'population', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'sqft_above', 'sqft_basement', 'yr_built',\n",
    "       'yr_renovated', 'yr_updated', 'has_golden_ratio', 'Poor', 'bare_min',\n",
    "       'average', 'good', 'high_qua', 'higher_qua', 'excellent_qua', 'mansion',\n",
    "       'No_Waterfront', 'Waterfront', 'water_sqft_lot', '98001', '98002',\n",
    "       '98003', '98004', '98005', '98006', '98022', '98023', '98030', '98031',\n",
    "       '98032', '98033', '98038', '98039', '98040', '98042', '98053', '98055',\n",
    "       '98058', '98074', '98075', '98077', '98092', '98102', '98105', '98106',\n",
    "       '98108', '98109', '98112', '98118', '98119', '98133', '98146', '98155',\n",
    "       '98168', '98178', '98188', '98198', '98199', 'niche_grade',\n",
    "       'yr_updated', 'ratio_liv_lot', 'niche_grade^2',\n",
    "       'niche_grade yr_updated', 'niche_grade ratio_liv_lot',\n",
    "       'yr_updated ratio_liv_lot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(effect_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[effect_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17290, 70)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school_grade',\n",
       " 'population',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'yr_updated',\n",
       " 'has_golden_ratio',\n",
       " 'Poor',\n",
       " 'bare_min',\n",
       " 'average',\n",
       " 'good',\n",
       " 'high_qua',\n",
       " 'higher_qua',\n",
       " 'excellent_qua',\n",
       " 'mansion',\n",
       " 'No_Waterfront',\n",
       " 'Waterfront',\n",
       " 'water_sqft_lot',\n",
       " '98001',\n",
       " '98002',\n",
       " '98003',\n",
       " '98004',\n",
       " '98005',\n",
       " '98006',\n",
       " '98022',\n",
       " '98023',\n",
       " '98030',\n",
       " '98031',\n",
       " '98032',\n",
       " '98033',\n",
       " '98038',\n",
       " '98039',\n",
       " '98040',\n",
       " '98042',\n",
       " '98053',\n",
       " '98055',\n",
       " '98058',\n",
       " '98074',\n",
       " '98075',\n",
       " '98077',\n",
       " '98092',\n",
       " '98102',\n",
       " '98105',\n",
       " '98106',\n",
       " '98108',\n",
       " '98109',\n",
       " '98112',\n",
       " '98118',\n",
       " '98119',\n",
       " '98133',\n",
       " '98146',\n",
       " '98155',\n",
       " '98168',\n",
       " '98178',\n",
       " '98188',\n",
       " '98198',\n",
       " '98199',\n",
       " 'niche_grade',\n",
       " 'yr_updated',\n",
       " 'ratio_liv_lot',\n",
       " 'niche_grade^2',\n",
       " 'niche_grade yr_updated',\n",
       " 'niche_grade ratio_liv_lot',\n",
       " 'yr_updated ratio_liv_lot']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate your different models in order to determine the best model overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "alpha = 0.05 \n",
    "#ANOVA Test Setup\n",
    "formula = 'price~C(floors)'\n",
    "lm_condition = smf.ols(formula, hf).fit()\n",
    "anova_condition = sm.stats.anova_lm(lm_condition, type=2)\n",
    "if anova_condition[\"PR(>F)\"][0] < alpha:\n",
    "    print(\"The number of floors has a statistically significant impact on average property value\")\n",
    "    print(\"Conditions F-statisic Probability: \", anova_condition[\"PR(>F)\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_waterfront = hf[(hf['Waterfront'] == 1)]\n",
    "waterfront_price = is_waterfront.price\n",
    "no_waterfront = hf[(hf['Waterfront'] == 0)]\n",
    "notwaterfront_price = no_waterfront.price\n",
    "alpha = 0.05\n",
    "waterfront_p_val = stats.ttest_ind(waterfront_price, notwaterfront_price, equal_var=False)[1]\n",
    "print(\"Waterfront vs No Waterfront T-test P Value: \", waterfront_p_val)\n",
    "if waterfront_p_val < alpha:\n",
    "    print(\"The P value is less than alpha, reject null-hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 \n",
    "#ANOVA Test Setup\n",
    "formula = 'price~C(bedrooms)'\n",
    "lm_condition = smf.ols(formula, hf).fit()\n",
    "anova_condition = sm.stats.anova_lm(lm_condition, type=2)\n",
    "if anova_condition[\"PR(>F)\"][0] < alpha:\n",
    "    print(\"The number of bedrooms has a statistically significant impact on average property value\")\n",
    "    print(\"Conditions F-statisic Probability: \", anova_condition[\"PR(>F)\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8:  Refit your best model to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save your final model using pickle.\n",
    "\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_fit_pickle_origin(df_features, target):\n",
    "    \"\"\"\n",
    "    Scaling df with features,\n",
    "    Fit linear model with scaled features\n",
    "    Create pickle file with Scaler and Model\n",
    "    params: \n",
    "            df_features - most important features \n",
    "            target - Series\n",
    "    \"\"\"\n",
    "#     scaler = StandardScaler()\n",
    "#     # fit the scaler to the training data\n",
    "#     scaler.fit(df_features)\n",
    "#     #transform the training data\n",
    "#     scaled_data = scaler.transform(df_features)\n",
    "#     #create dataframe\n",
    "#     df_features_scaled = pd.DataFrame(data=scaled_data, columns=df_features.columns, index=df_features.index)\n",
    "    lm_final = LinearRegression()\n",
    "#     #fit the linear regression to the data\n",
    "    lm_final = lm_final.fit(df_features, target)\n",
    "    pickle_out = open(\"model.pickle\",\"wb\")\n",
    "    pickle.dump(lm_final, pickle_out)\n",
    "    pickle_out.close()\n",
    "#     pickle_out = open('scaler.pickle', \"wb\")\n",
    "#     pickle.dump(scaler, pickle_out)\n",
    "#     pickle_out.close()\n",
    "    return print(' CONGATS !!! You sucessfuly created you pickles for SCALER and MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CONGATS !!! You sucessfuly created you pickles for SCALER and MODEL\n"
     ]
    }
   ],
   "source": [
    "scale_fit_pickle_origin(final_df, hf['price'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
