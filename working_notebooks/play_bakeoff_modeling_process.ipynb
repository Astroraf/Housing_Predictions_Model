{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kings County Housing Prices Bakeoff\n",
    "\n",
    "Below are a list of steps that you should take while trying to complete your bake-off entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm \n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.read_csv('kc_house_data_train.csv')\n",
    "zipfile = \"Zip_Codes-shp\"\n",
    "street_map = gpd.read_file(zipfile)\n",
    "crs = {'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17290"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'date', 'price', 'bedrooms', 'bathrooms',\n",
       "       'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition',\n",
       "       'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
       "       'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis \n",
    "    \n",
    "Become familiar with the data.  Look to see if there are any extreme values.  \n",
    "\n",
    "Additionally create data visualizations to determine if there are any relationships between your features and your target variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram\n",
    "sns.distplot(hf['price'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(hf['price'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(hf['price'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % hf['price'].skew())\n",
    "print(\"Kurtosis: %f\" % hf['price'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,15))\n",
    "street_map.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqliv = hf.loc[hf['sqft_living'] <= 6850]\n",
    "len(sqliv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlot = hf.loc[hf['sqft_lot'] <= 425000]\n",
    "len(sqlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floors = hf.loc[hf['floors'] <= 3.0]\n",
    "len(floors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = hf.loc[hf['view'] >= 3]\n",
    "len(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = hf.loc[hf['condition'] >= 5 ]\n",
    "len(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sqabove = hf.loc[hf['sqft_above'] <= 5800]\n",
    "len(sqabove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqliv15 = hf.loc[hf['sqft_living15'] <= 4820]\n",
    "len(sqliv15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlot15 = hf.loc[hf['sqft_lot15'] <= 250000]\n",
    "len(sqlot15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqbase = hf.loc[hf['sqft_basement'] <= 2180]\n",
    "len(sqbase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf[hf['bathrooms'] >= 5.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(hf['long'], hf['lat'])]\n",
    "geometry[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.GeoDataFrame(hf,\n",
    "                         crs = crs,\n",
    "                         geometry = geometry)\n",
    "geo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,15))\n",
    "street_map.plot(ax = ax, alpha = 0.4, color = 'grey')\n",
    "# geo_df[geo_df['Unnamed: 0'] >= 1000].plot(ax=ax, markersize = 20, color = 'blue', marker = \"^\", label = \"Housing ID\")\n",
    "# geo_df[geo_df['Unnamed: 0'] <= 1000].plot(ax=ax, markersize = 20, color = 'red', marker = \"o\", label = \"Housing ID\")\n",
    "geo_df[geo_df['price'] <= 7000000].plot(ax=ax, markersize = 20, color = 'green', marker = \"+\", label = \"Housing ID\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf[500:540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Set up  matplotlib figure (might have to play around with the \n",
    "# figsize if your labels aren't so legible and you don't want\n",
    "# to mess with the labels using matplotlib)\n",
    "f, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "# Create an upper triangular matrix to use to get rid of duplicate/\n",
    "# useless values\n",
    "mask = np.zeros_like(hf.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# plot the heatmap\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(hf.corr(), mask=mask, square=True)\n",
    "    \n",
    "# fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "# credit: https://github.com/mwaskom/seaborn/issues/1773 SalMac86's post\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.show() # ta-da!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_corr = hf[hf.columns[:]].corr()['price'][:] \n",
    "price_corr.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hf['bedrooms'], hf['bathrooms'], marker ='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hf['price'], hf['bedrooms'], marker = '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hf['condition'], hf['grade'], marker = '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.unique(hf['price']), np.poly1d(np.polyfit(hf['price'], hf['bedrooms'], 1))(np.unique(hf['price'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.regplot(hf['price'],hf['bedrooms'], scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(hf['price'],hf['bathrooms'], scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf[hf['sqft_living'] >= 12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['yr_renovated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7,2, figsize = (20, 20))\n",
    "\n",
    "\n",
    "sns.boxplot(ax = axes[0,0], data = hf['bedrooms'], orient = 'h')\n",
    "sns.boxplot(ax = axes[0,1], data = hf['bathrooms'], orient = 'h')\n",
    "sns.boxplot(ax = axes[1,1], data = hf['sqft_living'], orient = 'h')\n",
    "sns.boxplot(ax = axes[2,0], data = hf['sqft_lot'], orient = 'h')\n",
    "sns.boxplot(ax = axes[2,1], data = hf['floors'], orient = 'h')\n",
    "sns.boxplot(ax = axes[3,0], data = hf['grade'], orient = 'h')\n",
    "sns.boxplot(ax = axes[3,1], data = hf['sqft_above'], orient = 'h')\n",
    "sns.boxplot(ax = axes[4,0], data = hf['sqft_basement'], orient = 'h')\n",
    "sns.boxplot(ax = axes[4,1], data = hf['yr_built'], orient = 'h')\n",
    "sns.boxplot(ax = axes[5,0], data = hf['yr_renovated'], orient = 'h')\n",
    "sns.boxplot(ax = axes[5,1], data = hf['zipcode'], orient = 'h')\n",
    "sns.boxplot(ax = axes[6,0], data = hf['sqft_living15'], orient = 'h')\n",
    "sns.boxplot(ax = axes[6,1], data = hf['sqft_lot15'], orient = 'h')\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hf.zipcode.unique()\n",
    "hf['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['price', 'sqft_living', 'sqft_lot', 'view',\n",
    "             'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15'\n",
    "    \n",
    "]\n",
    "\n",
    "categorical = ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'condition', 'grade', 'zipcode'\n",
    "    \n",
    "]\n",
    "\n",
    "houses = hf[numerical + categorical]\n",
    "\n",
    "houses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook', font_scale = 1.4)\n",
    "\n",
    "sns.distplot(\n",
    "    hf['price'], norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
    ").set(xlabel='price', ylabel='Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf[numerical].hist(bins=15, figsize=(30, 50), layout=(13, 2));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(30, 20))\n",
    "for variable, subplot in zip(categorical, ax.flatten()):\n",
    "    sns.countplot(hf[variable], ax=subplot)\n",
    "    for label in subplot.get_xticklabels():\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=hf['sqft_living'], y=hf['sqft_living15']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=hf['price'], y=hf['yr_built']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(4, 2, figsize=(30, 20))\n",
    "for var, subplot in zip(categorical, ax.flatten()):\n",
    "    sns.boxplot(x=var, y='price', data=hf, ax=subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nb = hf.groupby(['zipcode'])['price'].median().sort_values()\n",
    "sns.boxplot(x=hf['zipcode'], y=hf['price'], order=list(sorted_nb.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(hf1):\n",
    "    _,ax=plt.subplots(figsize=(25,20))\n",
    "    colormap=sns.diverging_palette(220,10,as_cmap=True)\n",
    "    sns.heatmap(hf.corr(),annot=True,cmap=colormap)\n",
    "    \n",
    "correlation_heatmap(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(20,15))\n",
    "plt.title(\"house prices by sqft_above\")\n",
    "plt.xlabel('sqft_above')\n",
    "plt.ylabel('house prices')\n",
    "sns.barplot(x='sqft_above',y='price',data=hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobed = (hf['bedrooms'] == 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf[(hf['bathrooms'] == 2)]\n",
    "\n",
    "#avgbathrooms = hf.loc[hf['bathrooms'] == 2].mean('bedrooms')\n",
    "avgbathrooms =  hf.groupby(hf['bathrooms'] == 1)['bedrooms'].mean()\n",
    "avgbathrooms[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avgbathrooms =  hf.groupby('bathrooms', as_index=False)['bedrooms'].mean()\n",
    "avgbathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hf['sqft_living'] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean up any issues (extreme values, etc.) with the data.  \n",
    "\n",
    "Remember that you can't just delete rows with extreme values. Similar observations might be present in the holdout data set, and you can't just delete those rows and not have a prediction for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_val_bed_bath(row):\n",
    "    \"\"\"\n",
    "    Checking extreame number of rooms in the house\n",
    "    \"\"\"\n",
    "    if row['bedrooms'] == 0:\n",
    "        row['bedrooms'] = row['floors']\n",
    "    if row['bathrooms'] < 1:\n",
    "        row['bathrooms'] = 1\n",
    "    if row['bedrooms'] > 10 :\n",
    "        row['bedrooms'] = 10\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(zero_val_bed_bath, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.drop(columns = ['Unnamed: 0', 'id', 'view', 'sqft_living15', 'sqft_lot15'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate new features that you think could be important.\n",
    "\n",
    "After doing this, you will want to go back to steps 2 and 3 to investigate these new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['yr_updated'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yr_update(row):\n",
    "    \n",
    "    if row['yr_renovated'] == 0:\n",
    "        row['yr_updated'] = 2021 - row['yr_built']\n",
    "    if row['yr_renovated'] != 0:\n",
    "        row['yr_updated'] = 2021 - row['yr_built']\n",
    "        \n",
    "    return row \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(yr_update, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['yr_ren'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yr_ren(row):\n",
    "    \n",
    "    if row['yr_renovated'] == 0:\n",
    "        row['yr_ren'] = 0\n",
    "    if row['yr_renovated'] != 0:\n",
    "        row['yr_ren'] = 2021 - row['yr_built']\n",
    "        \n",
    "    return row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(yr_ren, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['percent_bedbath'] = np.nan\n",
    "hf['has_golden_ratio'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off of bathrooms pros and housetipster \n",
    "\n",
    "def ratio_bed_bath(row):\n",
    "    \n",
    "    ratio_bed_bath = row['bathrooms'] / row['bedrooms']\n",
    "    golden_ratio = (2/3)\n",
    "    row['percent_bedbath'] = abs(golden_ratio - ratio_bed_bath) \n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(ratio_bed_bath, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ratio_range(row):\n",
    "    golden_ratio = (2/3)\n",
    "    golden_ratio_plus = golden_ratio + (golden_ratio * .10)\n",
    "    golden_ratio_minus = golden_ratio - (golden_ratio * .10)\n",
    "    \n",
    "    if row['percent_bedbath'] <= golden_ratio_plus and row['percent_bedbath'] >= golden_ratio_minus:\n",
    "            row['has_golden_ratio'] = 1\n",
    "    else:\n",
    "        row['has_golden_ratio'] = 0\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(cal_ratio_range, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['ratio_liv_lot'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_living_lot(row):\n",
    "    \n",
    "    row['ratio_liv_lot'] = row['sqft_lot'] / row['sqft_living']\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(ratio_living_lot, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Identify a categorical variable in the data set and create dummy columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.concat([hf, pd.get_dummies(hf['zipcode'])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.drop(columns = 'zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.concat([hf, pd.get_dummies(hf['grade'])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.drop(columns = 'grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns = hf.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest g: 1\n",
    "# low g: 3 Falls short of minimum building standards. Normally cabin or inferior structure.\n",
    "\n",
    "# dnmc: 4 Generally older, low quality construction. Does not meet code.\n",
    "\n",
    "# poor: 5 Low construction costs and workmanship. Small, simple design.\n",
    "\n",
    "# bare_min: 6 Lowest grade currently meeting building code. Low quality materials and simple designs.\n",
    "\n",
    "# average: 7 Average grade of construction and design. Commonly seen in plats and older sub-divisions.\n",
    "\n",
    "# above_avg: 8 Just above average in construction and design. Usually better materials in both the exterior and interior finish work.\n",
    "\n",
    "# good: 9 Better architectural design with extra interior and exterior design and quality.\n",
    "\n",
    "# high_qua: 10 Homes of this quality generally have high quality features. Finish work is better and more design quality is seen in the floor plans. Generally have a larger square footage.\n",
    "\n",
    "# higher_qua: 11 Custom design and higher quality finish work with added amenities of solid woods, bathroom fixtures and more luxurious options.\n",
    "\n",
    "# excellent qua: 12 Custom design and excellent builders. All materials are of the highest quality and all conveniences are present.\n",
    "\n",
    "# mansion: 13 Generally custom designed and built. Mansion level. Large amount of highest quality cabinet work, wood trim, marble, entry ways etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.rename(columns={'1': 'lowest_g', '3': 'low_g', '4':'dnmc', '5':'Poor', '6':'bare_min', \n",
    "                   '7':'average', '8':'above_avg', '9':'good', '10':'high_qua', '11':'higher_qua',\n",
    "                   '12':'excellent_qua', '13':'mansion' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns[60:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        'sqft_living', 'sqft_lot', 'floors',\n",
    "       'waterfront', 'condition', 'sqft_above', 'sqft_basement',\n",
    "       'yr_built', 'yr_renovated', 'percent_bedbath', 'has_golden_ratio',\n",
    "       'ratio_liv_lot', 'lowest_g',\n",
    "       'low_g', 'dnmc', 'Poor', 'bare_min', 'average', 'above_avg', 'good',\n",
    "       'high_qua', 'higher_qua', 'excellent_qua', 'mansion', '98001', '98002', \n",
    "       '98003', '98004', '98005', '98006',\n",
    "       '98007', '98008', '98010', '98011', '98014', '98019', '98022', '98023',\n",
    "       '98024', '98027', '98028', '98029', '98030', '98031', '98032', '98033',\n",
    "       '98034', '98038', '98039', '98040', '98042', '98045', '98052', '98053',\n",
    "       '98055', '98056', '98058', '98059', '98065', '98070', '98072', '98074',\n",
    "       '98075', '98077', '98092', '98102', '98103', '98105', '98106', '98107',\n",
    "       '98108', '98109', '98112', '98115', '98116', '98117',\n",
    "       '98118', '98119', '98122', '98125', '98126', '98133', '98136', '98144',\n",
    "       '98146', '98148', '98155', '98166', '98168', '98177', '98178', '98188',\n",
    "       '98198', '98199']\n",
    "\n",
    "hf_features = hf[features]\n",
    "target = hf['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) There is a column that gives the date for when the house was sold, how could this be useful in your model? How might you transform the current column to a more useful feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "hf['date'] = pd.to_datetime(hf['date'], format = '%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns = hf.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['yr_ren']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) There are columns for when the house was built and when it was renovated.  How could you use these columns to create a new column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Non-linear transformations</ins>\n",
    "\n",
    "### 4.4) Create a polynomial feature for two of your continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_basement', 'yr_ren', 'yr_updated']\n",
    "\n",
    "poly_ft = hf[features]\n",
    "target = hf['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_df (df, degree):\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_data = poly.fit_transform(df)\n",
    "    poly_columns = poly.get_feature_names(df.columns)\n",
    "    df_poly = pd.DataFrame(poly_data, columns=poly_columns)\n",
    "    return df_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df = poly_df(poly_ft, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_2 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_2 = lm_2.fit(df_poly, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(df_poly, target, random_state=34,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lr_poly = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lr_poly = lr_poly.fit(X_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = lr_poly.predict(X_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_poly = np.sqrt(metrics.mean_squared_error(y_train_poly, train_preds))\n",
    "\n",
    "print('Root Mean Squared Error:' , train_rmse_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Create an interaction feature between a binary variable (dummy variable) and a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# waterfront times sqft_lot\n",
    "hf = pd.concat([hf, pd.get_dummies(hf['waterfront'])], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.rename(columns={0: \"No_Waterfront\", 1: \"Waterfront\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['water_sqft_lot'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_lot(row):\n",
    "    if row['waterfront'] == 1:\n",
    "        row['water_sqft_lot'] = row['Waterfront'] * row['sqft_lot'] \n",
    "    if row['waterfront'] == 0:\n",
    "        row['water_sqft_lot'] = 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.apply(water_lot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.drop(columns='waterfront')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train-Test Split\n",
    "\n",
    "If you plan on doing any scaling of your data, make sure it is done at the appropriate time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "         'sqft_lot', 'floors',\n",
    "        'condition', 'sqft_above',\n",
    "       'yr_built', 'yr_renovated', 'percent_bedbath', 'has_golden_ratio',\n",
    "       'ratio_liv_lot', 'lowest_g',\n",
    "       'low_g', 'dnmc', 'Poor', 'bare_min', 'average', 'above_avg', 'good',\n",
    "       'high_qua', 'higher_qua', 'excellent_qua', 'mansion', '98001', '98002', \n",
    "       '98003', '98004', '98005', '98006',\n",
    "       '98007', '98008', '98010', '98011', '98014', '98019', '98022', '98023',\n",
    "       '98024', '98027', '98028', '98029', '98030', '98031', '98032', '98033',\n",
    "       '98034', '98038', '98039', '98040', '98042', '98045', '98052', '98053',\n",
    "       '98055', '98056', '98058', '98059', '98065', '98070', '98072', '98074',\n",
    "       '98075', '98077', '98092', '98102', '98103', '98105', '98106', '98107',\n",
    "       '98108', '98109', '98112', '98115', '98116', '98117',\n",
    "       '98118', '98119', '98122', '98125', '98126', '98133', '98136', '98144',\n",
    "       '98146', '98148', '98155', '98166', '98168', '98177', '98178', '98188',\n",
    "       '98198', '98199', 'No_Waterfront', 'Waterfront', 'water_sqft_lot']\n",
    "\n",
    "hf_features = hf[features]\n",
    "target = hf['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Perform a train-test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(df, features, target):\n",
    "    df_features = df[features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=34,test_size=0.2)\n",
    "    #instantiate a linear regression object\n",
    "    lm = linear_model.LinearRegression()\n",
    "\n",
    "    #fit the linear regression to the data\n",
    "    lm = lm.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = lm.predict(X_train)\n",
    "    \n",
    "    train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "    train_mse = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "   \n",
    "    # Test Set\n",
    "    y_pred = lm.predict(X_test)\n",
    "    \n",
    "    #test_mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    #print('Mean Absolute Error:' + str(metrics.mean_absolute_error(y_test, y_pred)))\n",
    "    #print('Mean Squared Error:' + str(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(hf, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Fit your scaler to training the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_poly_fts = [x for x in hf.columns if x not in poly_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.merge(poly_df, hf[not_poly_fts], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hf, target, random_state=34,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.select_dtypes(include=[\"number\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "scaled_data = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(data=scaled_data, columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Transform the testing set with the scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here \n",
    "scaled_test_data = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = pd.DataFrame(data=scaled_test_data, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here \n",
    "#your code here \n",
    "#instantiate a linear regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5) Use the model to predict on the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here \n",
    "y_train_pred = lm.predict(X_train)\n",
    "\n",
    "y_test_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6) Evaluate the training and test predictions using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here \n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)\n",
    "print('Test Root Mean Squared Error:' , test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7) Determine if your model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_percent = round(((train_rmse - test_rmse)/(train_rmse))*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}% difference\".format(model_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Utilize some different feature selection techniques before or in conjuction with fitting your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Utilize a filter method to identify some features to remove from the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#F-test\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_regression, k=70)\n",
    "\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selector.get_support()]\n",
    "removed_columns = X_train.columns[~selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(removed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_kbest = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_kbest.fit(X_train[selected_columns], y_train)\n",
    "\n",
    "y_train_kbest = lm_kbest.predict(X_train[selected_columns])\n",
    "\n",
    "\n",
    "trainK_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbest))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainK_rmse)\n",
    "\n",
    "y_kbest = lm_kbest.predict(X_test[selected_columns])\n",
    "\n",
    "testK_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbest))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testK_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round((testK_rmse - trainK_rmse)/ (trainK_rmse)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REFECV\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recursive feature eliminator that scores features by mean squared errors\n",
    "selector = RFECV(estimator=ols, step=2, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "selector.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe = X_train.columns[selector.support_]\n",
    "removed_rfe = X_train.columns[~selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_rfe = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_rfe = lm_rfe.fit(X_train[selected_rfe], y_train)\n",
    "\n",
    "y_rfe = lm_rfe.predict(X_train[selected_rfe])\n",
    "\n",
    "\n",
    "trainRFE_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_rfe))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainRFE_rmse)\n",
    "\n",
    "y_pred_rfe = lm_rfe.predict(X_test[selected_rfe])\n",
    "\n",
    "testRFE_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testRFE_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = round((testRFE_rmse - trainRFE_rmse)/ (trainRFE_rmse)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) After removing the features, re-run Step 5 and see if your new model performs better than the old model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_feat = ['yr_built',\n",
    " 'percent_bedbath',\n",
    " 'lowest_g',\n",
    " 'dnmc',\n",
    " 'Poor',\n",
    " 'bare_min',\n",
    " 'average',\n",
    " 'above_avg',\n",
    " 'good',\n",
    " 'high_qua',\n",
    " 'higher_qua',\n",
    " 'excellent_qua',\n",
    " 'mansion',\n",
    " '98001',\n",
    " '98002',\n",
    " '98003',\n",
    " '98004',\n",
    " '98005',\n",
    " '98006',\n",
    " '98007',\n",
    " '98008',\n",
    " '98010',\n",
    " '98011',\n",
    " '98014',\n",
    " '98019',\n",
    " '98022',\n",
    " '98023',\n",
    " '98024',\n",
    " '98027',\n",
    " '98028',\n",
    " '98029',\n",
    " '98030',\n",
    " '98031',\n",
    " '98032',\n",
    " '98033',\n",
    " '98034',\n",
    " '98038',\n",
    " '98039',\n",
    " '98040',\n",
    " '98042',\n",
    " '98045',\n",
    " '98052',\n",
    " '98053',\n",
    " '98055',\n",
    " '98056',\n",
    " '98058',\n",
    " '98059',\n",
    " '98065',\n",
    " '98070',\n",
    " '98072',\n",
    " '98074',\n",
    " '98075',\n",
    " '98077',\n",
    " '98092',\n",
    " '98102',\n",
    " '98103',\n",
    " '98105',\n",
    " '98106',\n",
    " '98107',\n",
    " '98108',\n",
    " '98109',\n",
    " '98112',\n",
    " '98115',\n",
    " '98116',\n",
    " '98117',\n",
    " '98118',\n",
    " '98119',\n",
    " '98122',\n",
    " '98125',\n",
    " '98133',\n",
    " '98136',\n",
    " '98144',\n",
    " '98146',\n",
    " '98148',\n",
    " '98155',\n",
    " '98166',\n",
    " '98168',\n",
    " '98177',\n",
    " '98178',\n",
    " '98188',\n",
    " '98198',\n",
    " '98199',\n",
    " 'No_Waterfront',\n",
    " 'Waterfront',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'yr_updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hf = hf[effect_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate your different models in order to determine the best model overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "alpha = 0.05 \n",
    "#ANOVA Test Setup\n",
    "formula = 'price~C(floors)'\n",
    "lm_condition = smf.ols(formula, hf).fit()\n",
    "anova_condition = sm.stats.anova_lm(lm_condition, type=2)\n",
    "if anova_condition[\"PR(>F)\"][0] < alpha:\n",
    "    print(\"The number of floors has a statistically significant impact on average property value\")\n",
    "    print(\"Conditions F-statisic Probability: \", anova_condition[\"PR(>F)\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_waterfront = hf[(hf['Waterfront'] == 1)]\n",
    "waterfront_price = is_waterfront.price\n",
    "no_waterfront = hf[(hf['Waterfront'] == 0)]\n",
    "notwaterfront_price = no_waterfront.price\n",
    "alpha = 0.05\n",
    "waterfront_p_val = stats.ttest_ind(waterfront_price, notwaterfront_price, equal_var=False)[1]\n",
    "print(\"Waterfront vs No Waterfront T-test P Value: \", waterfront_p_val)\n",
    "if waterfront_p_val < alpha:\n",
    "    print(\"The P value is less than alpha, reject null-hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 \n",
    "#ANOVA Test Setup\n",
    "formula = 'price~C(bedrooms)'\n",
    "lm_condition = smf.ols(formula, hf).fit()\n",
    "anova_condition = sm.stats.anova_lm(lm_condition, type=2)\n",
    "if anova_condition[\"PR(>F)\"][0] < alpha:\n",
    "    print(\"The number of bedrooms has a statistically significant impact on average property value\")\n",
    "    print(\"Conditions F-statisic Probability: \", anova_condition[\"PR(>F)\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8:  Refit your best model to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(final_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.transform(final_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features_scaled = pd.DataFrame(data=final_hf[selected_columns], columns=final_hf.columns, index=final_hf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_final = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_final = lm.fit(scale_df[selected_columns], hf['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    lm_final = LinearRegression()\n",
    "#     #fit the linear regression to the data\n",
    "    lm_final = lm_final.fit(final_hf, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save your final model using pickle.\n",
    "\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle_out = open(\"model.pickle\",\"wb\")\n",
    "pickle.dump(lm_final, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_out = open('scaler.pickle', \"wb\")\n",
    "# pickle.dump(scaler, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(selected_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
